{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Deo0-usWoBBx"
   },
   "source": [
    "# Exercises Sheet 2 Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Exercise 1.1\n",
    "print (\"Using operator AND\")\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "d = np.array([0, 0, 0, 1])\n",
    "\n",
    "# Display input, expected output (d), and perceptron output\n",
    "for i in range(len(X)):\n",
    "    print(f\"Input: {X[i]} | Target: {d[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.2\n",
    "# Initialize w0, w1, and w2 to small random values\n",
    "# np.random.seed(9)  # For reproducibility\n",
    "w0 = np.random.rand()\n",
    "print (f\"w0 (bias) is {w0}\")\n",
    "w1 = np.random.rand()\n",
    "print (f\"w1 is {w1}\")\n",
    "w2 = np.random.rand()\n",
    "print (f\"w2 is {w2}\")\n",
    "\n",
    "# Activation function f(s)#\n",
    "def activation(s):\n",
    "    return 1 if s > 0.5 else 0\n",
    "\n",
    "# Calculate outputs for each input pattern\n",
    "o = []\n",
    "for x1, x2 in X:\n",
    "    s = w0 + w1 * x1 + w2 * x2\n",
    "    o.append(activation(s))\n",
    "    #o.append(s)\n",
    "\n",
    "o = np.array(o)\n",
    "print(f\"Output vector o: {o}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.3\n",
    "# Calculate the error e = d - o\n",
    "e = d - o\n",
    "\n",
    "# Display input, expected output (d), perceptron output (o), and the difference (error e)\n",
    "for i in range(len(X)):\n",
    "    print(f\"Input: {X[i]} | Target: {d[i]} | Output: {o[i]} | Error: {e[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "alpha = 1e-4\n",
    "\n",
    "# Initialize update terms for w0, w1, and w2\n",
    "delta_w0 = 0\n",
    "delta_w1 = 0\n",
    "delta_w2 = 0\n",
    "\n",
    "# Update each weight based on the error for each input pattern\n",
    "for i in range(len(X)):\n",
    "    x1, x2 = X[i]\n",
    "    delta_w0 += alpha * e[i]\n",
    "    delta_w1 += alpha * x1 * e[i]\n",
    "    delta_w2 += alpha * x2 * e[i]\n",
    "\n",
    "# Display the update terms\n",
    "print(f\"âˆ†w0: {delta_w0}\")\n",
    "print(f\"âˆ†w1: {delta_w1}\")\n",
    "print(f\"âˆ†w2: {delta_w2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimal_found = False\n",
    "optimal_epoch = None\n",
    "\n",
    "# Training parameters\n",
    "alpha = 10e-4  # Learning rate\n",
    "epochs = 500  # Number of epochs\n",
    "\n",
    "# Activation function\n",
    "def activation(s):\n",
    "    return 1 if s > 0.5 else 0\n",
    "\n",
    "# Lists to store values for plotting\n",
    "errors = []\n",
    "weights_w0 = []\n",
    "weights_w1 = []\n",
    "weights_w2 = []\n",
    "\n",
    "# Training loop over epochs\n",
    "for epoch in range(epochs):\n",
    "    # Initialize update terms for each epoch\n",
    "    delta_w0 = 0\n",
    "    delta_w1 = 0\n",
    "    delta_w2 = 0\n",
    "\n",
    "    # Track cumulative error for the epoch\n",
    "    epoch_error = 0\n",
    "\n",
    "    # Process each input pattern\n",
    "    for i in range(len(X)):\n",
    "        x1, x2 = X[i]\n",
    "        \n",
    "        # Calculate output\n",
    "        s = w0 + w1 * x1 + w2 * x2\n",
    "        o = activation(s)\n",
    "\n",
    "        # Calculate error\n",
    "        e = d[i] - o\n",
    "        epoch_error += abs(e)  # Summing absolute error for tracking\n",
    "\n",
    "        # Update terms for weights\n",
    "        delta_w0 += alpha * e\n",
    "        delta_w1 += alpha * x1 * e\n",
    "        delta_w2 += alpha * x2 * e\n",
    "        print(f\"  Input: {X[i]}, Target: {d[i]}, Output: {o}, Error: {e}\")\n",
    "\n",
    "    # Update weights at the end of each epoch\n",
    "    w0 += delta_w0\n",
    "    w1 += delta_w1\n",
    "    w2 += delta_w2\n",
    "\n",
    "    # Print weights and cumulative error after each epoch\n",
    "    print(f\"End of Epoch {epoch + 1} | w0: {w0:.4f}, w1: {w1:.4f}, w2: {w2:.4f} | Total Error: {epoch_error}\")\n",
    "\n",
    "    if not optimal_found and epoch_error==0:\n",
    "        optimal_found = True\n",
    "        print(f\"The optimal solution was found on epoch {epoch + 1}!\")\n",
    "        optimal_epoch = epoch + 1\n",
    "\n",
    "\n",
    "    # Store values for plotting\n",
    "    errors.append(epoch_error)\n",
    "    weights_w0.append(w0)\n",
    "    weights_w1.append(w1)\n",
    "    weights_w2.append(w2)\n",
    "\n",
    "print(f\"The optimal solution was found on epoch {optimal_epoch}!\")\n",
    "\n",
    "# Plotting results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Error over epochs\n",
    "ax1.plot(range(1, epochs + 1), errors, marker='o', color='r')\n",
    "ax1.set_title(\"Error over Epochs\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Error\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot 2: Weight values over epochs\n",
    "ax2.plot(range(1, epochs + 1), weights_w0, marker='o', label=\"w0\", color='b')\n",
    "ax2.plot(range(1, epochs + 1), weights_w1, marker='o', label=\"w1\", color='g')\n",
    "ax2.plot(range(1, epochs + 1), weights_w2, marker='o', label=\"w2\", color='orange')\n",
    "ax2.set_title(\"Weights over Epochs\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Weight Value\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "num_points = 500\n",
    "\n",
    "# Generate points for class 'a'\n",
    "mean_a = [3, 3]\n",
    "cov_a = [[1, 0], [0, 1]]\n",
    "a = np.random.multivariate_normal(mean_a, cov_a, num_points)\n",
    "label_a = np.zeros((num_points, 1))  # Column of zeros for the first dataset\n",
    "a = np.hstack((a, label_a))  # Combine points with labels\n",
    "\n",
    "# Generate points for class 'b'\n",
    "mean_b = [-3, -3]\n",
    "cov_b = [[2, 0], [0, 5]]\n",
    "b = np.random.multivariate_normal(mean_b, cov_b, num_points) # .T #TODO ?\n",
    "label_b = np.ones((num_points, 1))  # Column of ones for the second dataset\n",
    "b = np.hstack((b, label_b))  # Combine points with labels\n",
    "\n",
    "# Join and shuffle the dataset\n",
    "dataset = np.vstack((a, b))\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Plot the dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(dataset[:, 0], dataset[:, 1], c=dataset[:, 2], cmap='viridis', marker='x')\n",
    "plt.axis('equal')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('2D Points Generated from Two Gaussian Distributions')\n",
    "plt.show()\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "df = pd.DataFrame(dataset, columns=['X1', 'X2', 'Label'])\n",
    "df.to_csv(\"generated_dataset.csv\", index=False)\n",
    "print(\"Dataset saved to 'my_data.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the generated dataset\n",
    "data = pd.read_csv(\"generated_dataset.csv\").values\n",
    "X = data[:, :2]  # Features (first two columns)\n",
    "y = data[:, 2]   # Labels (third column)\n",
    "\n",
    "# Perceptron parameters\n",
    "alpha = 1e-2  # Learning rate\n",
    "epochs = 50   # Number of epochs (adjustable for faster convergence)\n",
    "\n",
    "# Initialize weights randomly between 0 and 1\n",
    "w0, w1, w2 = np.random.rand(), np.random.rand(), np.random.rand()\n",
    "\n",
    "# Activation function\n",
    "def activation(s):\n",
    "    return 1 if s > 0.5 else 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Initialize update terms\n",
    "    delta_w0, delta_w1, delta_w2 = 0, 0, 0\n",
    "    epoch_error = 0  # Track total error\n",
    "\n",
    "    # Iterate over all data points\n",
    "    for i in range(len(X)):\n",
    "        x1, x2 = X[i]\n",
    "        \n",
    "        # Calculate output\n",
    "        s = w0 + w1 * x1 + w2 * x2\n",
    "        o = activation(s)\n",
    "\n",
    "        # Calculate error\n",
    "        e = y[i] - o\n",
    "        epoch_error += abs(e)  # Accumulate absolute error for the epoch\n",
    "\n",
    "        # Update weight terms based on error\n",
    "        delta_w0 += alpha * e\n",
    "        delta_w1 += alpha * x1 * e\n",
    "        delta_w2 += alpha * x2 * e\n",
    "\n",
    "    # Update weights at the end of each epoch\n",
    "    w0 += delta_w0\n",
    "    w1 += delta_w1\n",
    "    w2 += delta_w2\n",
    "\n",
    "    # Print weights and error after each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | w0: {w0:.4f}, w1: {w1:.4f}, w2: {w2:.4f} | Total Error: {epoch_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.8\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict labels using the trained perceptron\n",
    "predicted_labels = []\n",
    "for i in range(len(X)):\n",
    "    x1, x2 = X[i]\n",
    "    s = w0 + w1 * x1 + w2 * x2\n",
    "    o = activation(s)\n",
    "    predicted_labels.append(o)\n",
    "\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Separate points based on true and predicted labels\n",
    "a1 = X[(y == 0) & (predicted_labels == 1)]  # (a) First distribution, labeled 1\n",
    "a0 = X[(y == 0) & (predicted_labels == 0)]  # (b) First distribution, labeled 0\n",
    "b1 = X[(y == 1) & (predicted_labels == 1)]  # (c) Second distribution, labeled 1\n",
    "b0 = X[(y == 1) & (predicted_labels == 0)]  # (d) Second distribution, labeled 0\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(a1[:, 0], a1[:, 1], color='blue', marker='x', label='Class 0, Predicted 1')\n",
    "plt.scatter(a0[:, 0], a0[:, 1], color='cyan', marker='o', label='Class 0, Predicted 0')\n",
    "plt.scatter(b1[:, 0], b1[:, 1], color='orange', marker='x', label='Class 1, Predicted 1')\n",
    "plt.scatter(b0[:, 0], b0[:, 1], color='red', marker='o', label='Class 1, Predicted 0')\n",
    "\n",
    "# Set plot parameters\n",
    "plt.axis('equal')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Perceptron Classification of Two Distributions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 1.9\n",
    "# Corrected confusion matrix calculation\n",
    "def compute_confusion_matrix(y_true, y_pred):\n",
    "    # Identify unique class labels and map them to integer indices\n",
    "    classes = np.unique(y_true)\n",
    "    class_to_index = {label: idx for idx, label in enumerate(classes)}\n",
    "    \n",
    "    # Initialize matrix of zeros with shape based on number of unique classes\n",
    "    matrix = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    \n",
    "    # Fill the matrix by counting occurrences of (true, pred) label pairs\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        matrix[class_to_index[true], class_to_index[pred]] += 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = compute_confusion_matrix(y, predicted_labels)\n",
    "\n",
    "# Add labels to the matrix for display purposes\n",
    "cm_with_labels = np.vstack([\n",
    "    [\"\", \"Predicted 0:\", \"Predicted 1:\"],\n",
    "    [\"Actual 0:\", *cm[0]],\n",
    "    [\"Actual 1:\", *cm[1]]\n",
    "])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "for row in cm_with_labels:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 30\n",
    "metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "\n",
    "# Function to calculate metrics manually\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))  # True Positives\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))  # True Negatives\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))  # False Positives\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))  # False Negatives\n",
    "    \n",
    "    # Accuracy: the ratio of correct predictions (both true positives and true negatives) to total predictions\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Precision: the ratio of true positive predictions to all positive predictions (true positives + false positives)\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    \n",
    "    # Recall: the ratio of true positive predictions to all actual positives (true positives + false negatives)\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    \n",
    "    # F1 Score: the harmonic mean of precision and recall, a single metric balancing the two\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Run metric calculation for each test\n",
    "for _ in range(n_tests):\n",
    "    # Initialize weights randomly\n",
    "    w0, w1, w2 = np.random.rand(), np.random.rand(), np.random.rand()\n",
    "    \n",
    "    # Train the perceptron with new weights here (adjust this code to your training loop)\n",
    "    # e.g., train_perceptron(X, y, w0, w1, w2)\n",
    "\n",
    "    # Predict labels after training\n",
    "    predicted_labels = np.array([activation(w0 + w1 * x[0] + w2 * x[1]) for x in X])\n",
    "    \n",
    "    # Calculate metrics for current test\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y, predicted_labels)\n",
    "    \n",
    "    # Append current test metrics to the lists\n",
    "    metrics['accuracy'].append(accuracy)\n",
    "    metrics['precision'].append(precision)\n",
    "    metrics['recall'].append(recall)\n",
    "    metrics['f1'].append(f1)\n",
    "\n",
    "# Calculate and print average metrics across all tests\n",
    "avg_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "print(f\"Average Metrics over {n_tests} Tests:\")\n",
    "print(f\"Accuracy (ratio of correct predictions (both true positives and true negatives) to total predictions): \\n {avg_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision ratio of true positive predictions to all positive predictions (true positives + false positives): \\n {avg_metrics['precision']:.4f}\")\n",
    "print(f\"Recall (ratio of true positive predictions to all actual positives (true positives + false negatives)): \\n {avg_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score (the harmonic mean of precision and recall, a single metric balancing the two): \\n {avg_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "data = pd.read_csv(\"./irisData/bezdekIris.data\").values\n",
    "# print(data)\n",
    "\n",
    "def split_data_random(data, split_ratio=0.7):\n",
    "    # Shuffle the data\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    # Calculate the split index\n",
    "    split_index = int(len(data) * split_ratio)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    treino = data[:split_index]\n",
    "    teste = data[split_index:]\n",
    "\n",
    "    return treino, teste\n",
    "\n",
    "\n",
    "def classificador(mais_proximos):\n",
    "    \"\"\"\n",
    "    Returns the majority label given a list of closes neighbors from training data set\n",
    "    \"\"\"\n",
    "    label_counts = {}\n",
    "    for label in mais_proximos:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "    majority_label = max(label_counts, key=label_counts.get)\n",
    "    return majority_label\n",
    "\n",
    "\n",
    "def knn(plant, treino, k = 3):\n",
    "    # k should be odd to prevent race between two labels\n",
    "    closer_data_points = mais_proximos(plant, treino, k)\n",
    "    class_prevista = classificador(closer_data_points)\n",
    "    return class_prevista\n",
    "\n",
    "\n",
    "def mais_proximos(plant, treino, k=3):\n",
    "    distances = []\n",
    "    \n",
    "    for example in treino:\n",
    "        # Calculate Euclidean distance between `plant` and `example`\n",
    "        distance = math.sqrt(sum((plant[i] - example[i]) ** 2 for i in range(len(plant) - 1)))\n",
    "        distances.append((distance, example[-1]))  # Store the distance and label\n",
    "\n",
    "    # Sort distances and select the k nearest neighbors\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    nearest_neighbors = [label for _, label in distances[:k]]\n",
    "    \n",
    "    return nearest_neighbors\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def test_accuracy(teste, treino, k=3):\n",
    "    correct = 0\n",
    "    total = len(teste)\n",
    "    for plant in teste:\n",
    "        true_label = plant[-1] # last element is label\n",
    "        predicted_label = knn(plant, treino, k)\n",
    "        if predicted_label == true_label:\n",
    "            correct += 1\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of correct predictions k = 3\n",
    "\n",
    "train_data_set, test_data_set = split_data_random(data, split_ratio=0.7)\n",
    "test_accuracy(test_data_set, train_data_set, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of correct predictions k = 7\n",
    "\n",
    "train_data_set, test_data_set = split_data_random(data, split_ratio=0.7)\n",
    "test_accuracy(test_data_set, train_data_set, k=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of correct predictions k = 11\n",
    "\n",
    "train_data_set, test_data_set = split_data_random(data, split_ratio=0.7)\n",
    "test_accuracy(test_data_set, train_data_set, k=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "k_values = [3, 7, 11]\n",
    "repetitions = 30\n",
    "results = {k: [] for k in k_values}\n",
    "\n",
    "# Run experiment\n",
    "for k in k_values:\n",
    "    for _ in range(repetitions):\n",
    "        train_data_set, test_data_set = split_data_random(data, split_ratio=0.7)\n",
    "        accuracy = test_accuracy(test_data_set, train_data_set, k)\n",
    "        results[k].append(accuracy)\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([results[k] for k in k_values], labels=k_values)\n",
    "plt.title('K-NN Accuracy for Different Values of k (30 Trials)')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2.2 Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_predictions(teste, treino, k=3):\n",
    "    \"\"\"\n",
    "    Returns the true and predicted labels for the test set.\n",
    "    \"\"\"\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for plant in teste:\n",
    "        true_label = plant[-1]\n",
    "        predicted_label = knn(plant, treino, k)\n",
    "        \n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "    \n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "def compute_confusion_matrix(true_labels, predicted_labels):\n",
    "    # Identify unique classes and create a mapping from class names to indices\n",
    "    classes = sorted(list(set(true_labels)))\n",
    "    n_classes = len(classes)\n",
    "    class_to_index = {cls: i for i, cls in enumerate(classes)}\n",
    "    \n",
    "    # Initialize confusion matrix\n",
    "    confusion_matrix = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    \n",
    "    # Populate confusion matrix\n",
    "    for true_label, pred_label in zip(true_labels, predicted_labels):\n",
    "        true_idx = class_to_index[true_label]\n",
    "        pred_idx = class_to_index[pred_label]\n",
    "        confusion_matrix[true_idx, pred_idx] += 1\n",
    "    \n",
    "    # Format matrix with labels\n",
    "    formatted_matrix = [[\"\"] + [f\"Predicted {cls}:\" for cls in classes]]\n",
    "    for i, cls in enumerate(classes):\n",
    "        formatted_matrix.append([f\"Actual {cls}:\"] + list(confusion_matrix[i]))\n",
    "    \n",
    "    return formatted_matrix\n",
    "\n",
    "# Set k and split data\n",
    "k = 3  # Ensure k is the same for both accuracy and confusion matrix calculations\n",
    "train_data_set, test_data_set = split_data_random(data, split_ratio=0.7)\n",
    "\n",
    "# Calculate and print test accuracy\n",
    "accuracy = test_accuracy(test_data_set, train_data_set, k)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Compute true and predicted labels for confusion matrix\n",
    "true_labels, predicted_labels = compute_predictions(test_data_set, train_data_set, k)\n",
    "\n",
    "print(f\"True labels: {true_labels}\")\n",
    "print(f\"Predicted labels: {predicted_labels}\")\n",
    "\n",
    "cm = compute_confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "for row in cm:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With sklearn\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute and plot confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=np.unique(data[:, -1]))\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(data[:, -1]))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax)\n",
    "plt.title(f'Confusion Matrix for k={k}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 2.3\n",
    "\n",
    "K should always be an odd number to prevent race conditions like the case where there are the same number of neighbors from two different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - low \n",
    "# 1 - medium\n",
    "# 2 - high\n",
    "\n",
    "# 4.3 - 7.9 __ 1.2\n",
    "# 2.0 - 4.4 __ 0.73\n",
    "# 1.0 - 6.9 __ 1.967\n",
    "# 0.1 - 2.5 __ 0.8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dados= pd.read_csv('./irisData/bezdekIris.data').values\n",
    "\n",
    "a = 0\n",
    "for i in dados:\n",
    "    if i[0] >= 4.3 and i[0] < 5.5:\n",
    "        dados[a][0] = 0\n",
    "    elif i[0] >= 5.5 and i[0] < 6.7:\n",
    "        dados[a][0] = 1\n",
    "    else:\n",
    "        dados[a][0] = 2\n",
    "    \n",
    "    if i[1] >= 2.0 and i[1] < 2.73:\n",
    "        dados[a][1] = 0\n",
    "    elif i[1] >= 2.73 and i[1] < 3.46:\n",
    "        dados[a][1] = 1\n",
    "    else:\n",
    "        dados[a][1] = 2\n",
    "    \n",
    "    if i[2] >= 1.0 and i[2] < 2.967:\n",
    "        dados[a][2] = 0\n",
    "    elif i[2] >= 2.967 and i[2] < 4.934:\n",
    "        dados[a][2] = 1\n",
    "    else:\n",
    "        dados[a][2] = 2\n",
    "    \n",
    "    if i[3] >= 0.1 and i[0] < 0.9:\n",
    "        dados[a][3] = 0\n",
    "    elif i[3] >= 0.9 and i[3] < 1.7:\n",
    "        dados[a][3] = 1\n",
    "    else:\n",
    "        dados[a][3] = 2\n",
    "    \n",
    "    a +=1\n",
    "\n",
    "print(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 3 more databses, one with the low elements of the first column, one with the medium and one with the high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Part 1: Splitting the dataset based on the first column\n",
    "low_dataset = [row for row in dados if row[0] == 0] # has all the elements with value low in the first column\n",
    "medium_dataset = [row for row in dados if row[0] == 1] # has all the elements with value medium in the first column\n",
    "high_dataset = [row for row in dados if row[0] == 2] # has all the elements with value high in the first column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Entropy (Measure of disorder in the dataset, heigher entropy means the dataset has a bigger mixture of classes)\n",
    "\n",
    "General formula for entropy:\n",
    "$$\n",
    "H(S) = -\\sum_{i=1}^{n} p(i) \\log_2 p(i)\n",
    "$$\n",
    "We are using binary classification, just for *Iris-setosa* right now, so $(p+)$ is the probability on the dataset of being an *Iris-setosa* and $(p-)$ the probability of not being an *Iris-setosa*. So the calculation will be:\n",
    "$$\n",
    " \\text{entropy}(S) = - (p+) \\cdot \\log_2(p+) - (p-) \\cdot \\log_2(p-) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Entropy\n",
    "def entropy(data,tipo):\n",
    "    dadosT, prob_classe = calc_probs2(data)\n",
    "    if(tipo == 0): # setosa\n",
    "        p_plus = prob_classe[0]\n",
    "        p_minus = prob_classe[1] + prob_classe[2]\n",
    "    elif(tipo == 1): # virticolor\n",
    "        p_plus = prob_classe[1]\n",
    "        p_minus = prob_classe[0] + prob_classe[2]\n",
    "    else: # virginica\n",
    "        p_plus = prob_classe[2]\n",
    "        p_minus = prob_classe[1] + prob_classe[0]\n",
    "        \n",
    "    # if the classes are all the same, there is no variation, no entropy\n",
    "    if p_minus == 0:\n",
    "        return 0 \n",
    "    if p_plus == 0:\n",
    "        return 0\n",
    "\n",
    "    entropy = -p_plus * math.log2(p_plus) - p_minus * math.log2(p_minus)\n",
    "    return entropy\n",
    "\n",
    "# Print entropies\n",
    "print(\"Complete dataset entropy:\", entropy(dados, 0))\n",
    "print(\"Low dataset entropy:\", entropy(low_dataset, 0))\n",
    "print(\"Medium dataset entropy:\", entropy(medium_dataset, 0))\n",
    "print(\"High dataset entropy:\", entropy(high_dataset, 0))\n",
    "\n",
    "# Entropy with all classes\n",
    "def calculate_entropy_full(data):\n",
    "    \"\"\"Calculate the entropy of a dataset.\"\"\"\n",
    "    label_counts = Counter(row[-1] for row in data)\n",
    "    total = len(data)\n",
    "    entropy = 0.0\n",
    "    for count in label_counts.values():\n",
    "        probability = count / total\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "'''\n",
    "def calculate_entropy(data):\n",
    "    \"\"\"Calculate the entropy of a dataset.\"\"\"\n",
    "    label_counts = Counter(row[-1] for row in data)\n",
    "    total = len(data)\n",
    "    entropy = 0.0\n",
    "    for count in label_counts.values():\n",
    "        probability = count / total\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "print()\n",
    "print(\"Complete dataset entropy without target setosa:\", calculate_entropy(dados))\n",
    "print(\"Low dataset entropy without target setosa:\", calculate_entropy(low_dataset))\n",
    "print(\"Medium dataset entropy without target setosa:\", calculate_entropy(medium_dataset))\n",
    "print(\"High dataset entropy without target setosa:\", calculate_entropy(high_dataset))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Gain\n",
    "\n",
    "\n",
    "- Information Gain (IG) is a measure used in decision trees to quantify the effectiveness of a feature in splitting the dataset into classes. It calculates the reduction in entropy (uncertainty) of the target variable (class labels) when a particular feature is known.\n",
    "- In simpler terms, Information Gain helps us understand how much a particular feature contributes to making accurate predictions in a decision tree. Features with higher Information Gain are considered more informative and are preferred for splitting the dataset, as they lead to nodes with more homogenous classes.\n",
    "[(Source)](https://www.geeksforgeeks.org/information-gain-and-mutual-information-for-machine-learning/)\n",
    "\n",
    "$$\n",
    "    \\text{gain}(S,a) = \\text{entropy}(S) - \\frac{\\sum_v(|S_v| \\times \\text{entropy}(S_v))}{|S|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate gain for a given feature (targeting class \"Setosa\")\n",
    "def calculate_gain(S, a):\n",
    "    # Step 1: Calculate entropy of the full dataset (for class Setosa)\n",
    "    total_entropy = entropy(S,a) # calculate_entropy_full(S) ?\n",
    "\n",
    "    # Partition in subsets\n",
    "    low_dataset = [row for row in dados if row[a] == 0] # has all the elements with value low in the first column\n",
    "    medium_dataset = [row for row in dados if row[a] == 1] # has all the elements with value medium in the first column\n",
    "    high_dataset = [row for row in dados if row[a] == 2] # has all the elements with value high in the first column\n",
    "\n",
    "    # Step 3: Calculate the weighted entropy sum for each subset\n",
    "    subsets = [low_dataset, medium_dataset, high_dataset]\n",
    "    weighted_entropy_sum = 0\n",
    "    \n",
    "    for subset in subsets:\n",
    "        subset_entropy = entropy(subset,a) # calculate_entropy_full(subset) ?\n",
    "        weighted_entropy = (len(subset)) * subset_entropy  # Weighted by subset size\n",
    "        weighted_entropy_sum += weighted_entropy         # Add to the weighted sum\n",
    "    \n",
    "    # Step 4: Calculate gain by subtracting weighted entropy sum from total entropy\n",
    "    gain = total_entropy - (weighted_entropy_sum / len(S))\n",
    "    return gain\n",
    "\n",
    "print (\"Gain with split on first feature:\")\n",
    "print(calculate_gain(dados, 0))\n",
    "\n",
    "# Example usage:\n",
    "print()\n",
    "print (\"Gain on all features:\")\n",
    "print(f\"Gain with split on first column: {calculate_gain(dados, 0)}\")\n",
    "print(f\"Gain with split on second column: {calculate_gain(dados, 1)}\")\n",
    "print(f\"Gain with split on third column: {calculate_gain(dados, 2)}\")\n",
    "print(f\"Gain with split on fourth column: {calculate_gain(dados, 3)}\")\n",
    "\n",
    "print(f\"Biggest gain: {max(calculate_gain(dados, 0), calculate_gain(dados, 1), calculate_gain(dados, 2), calculate_gain(dados, 3))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Explain how to build a decision tree with this information\n",
    "\n",
    "A decision tree uses information gain to iteratively split the dataset, creating a hierarchical structure that classifies data based on feature values. By recursively selecting the feature that provides the highest information gain at each level, the tree grows to distinguish between classes with the fewest splits, creating an intuitive and interpretable model for classification.\n",
    "\n",
    "```txt\n",
    "             [Petal Width]\n",
    "           /     |         \\\n",
    "       Low      Medium       High\n",
    "      /           |              \\\n",
    "  [Leaf: Setosa] [Petal Length]  [Leaf: Virginica]\n",
    "                /       \\\n",
    "            Short       Long\n",
    "            /              \\\n",
    "     [Leaf: Versicolor]   [Leaf: Virginica]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
